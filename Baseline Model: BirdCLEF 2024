{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":19596,"databundleVersionId":1292430,"sourceType":"competition"},{"sourceId":25954,"databundleVersionId":2091745,"sourceType":"competition"},{"sourceId":33246,"databundleVersionId":3221581,"sourceType":"competition"},{"sourceId":44224,"databundleVersionId":5188730,"sourceType":"competition"},{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"},{"sourceId":1487019,"sourceType":"datasetVersion","datasetId":726237},{"sourceId":1487116,"sourceType":"datasetVersion","datasetId":726312},{"sourceId":1664376,"sourceType":"datasetVersion","datasetId":985270},{"sourceId":5181249,"sourceType":"datasetVersion","datasetId":3012199},{"sourceId":5195317,"sourceType":"datasetVersion","datasetId":3020983}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Package imports","metadata":{}},{"cell_type":"code","source":"try: import fastkaggle\nexcept ModuleNotFoundError:\n    !pip install -Uq fastkaggle\n\nfrom fastkaggle import *\n\n# WandB for experiment tracking\n# Import wandb library for logging and tracking experiments\nimport wandb\n\n# Try to get the API key from Kaggle secrets\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"WANDB\")\n    # Login to wandb with the API key\n    wandb.login(key=api_key)\n    # Set anonymous mode to None\n    anonymous = None\nexcept:\n    # If Kaggle secrets are not available, set anonymous mode to 'must'\n    anonymous = 'must'\n    # Login to wandb anonymously and relogin if needed\n    wandb.login(anonymous=anonymous, relogin=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:56:25.009955Z","iopub.execute_input":"2024-04-18T14:56:25.010405Z","iopub.status.idle":"2024-04-18T14:56:46.126113Z","shell.execute_reply.started":"2024-04-18T14:56:25.010365Z","shell.execute_reply":"2024-04-18T14:56:46.124562Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data processing\n* Download dataset\n* Explore dataset\n* Convert audio files into Mel Spectrograms using librosa\n* Split data (?)","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # Audio duration, sample rate, and length\n    duration = 10 # second\n    sample_rate = 32000\n    audio_len = duration*sample_rate","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:03:01.815782Z","iopub.execute_input":"2024-04-18T15:03:01.816341Z","iopub.status.idle":"2024-04-18T15:03:01.823522Z","shell.execute_reply.started":"2024-04-18T15:03:01.816303Z","shell.execute_reply":"2024-04-18T15:03:01.821886Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"comp = \"birdclef-2024\"\npath = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')\npath","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:59:29.794277Z","iopub.execute_input":"2024-04-18T14:59:29.795411Z","iopub.status.idle":"2024-04-18T14:59:46.407479Z","shell.execute_reply.started":"2024-04-18T14:59:29.795369Z","shell.execute_reply":"2024-04-18T14:59:46.405974Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def load_audio(file_path)\n    audio, sr = librosa.load(filepath)\n    return audio, sr\ndef get_spectrogram(audio):\n    spec = librosa.feature.melspectrogram(y=audio,\n                                         sr = CFG.sample_rate,\n                                         n_mels = )\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For Spectrogram, SpecAug layers\n!pip install -q /kaggle/input/tensorflow-extra-lib-ds/tensorflow_extra-1.0.2-py3-none-any.whl --no-deps\n\n# efficientnet with filter stride reduction (FSR)\n!pip install -qU git+https://github.com/awsaf49/efficientnet-spec","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:42:15.392673Z","iopub.execute_input":"2024-04-18T14:42:15.393417Z","iopub.status.idle":"2024-04-18T14:42:39.683279Z","shell.execute_reply.started":"2024-04-18T14:42:15.393383Z","shell.execute_reply":"2024-04-18T14:42:39.681435Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print('np:', np.__version__)\nprint('pd:', pd.__version__)\nprint('sklearn:', sklearn.__version__)\nprint('librosa:', librosa.__version__)\nprint('tf:', tf.__version__)\n\nprint('tfio:', tfio.__version__)\nprint('w&b:', wandb.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:42:39.686056Z","iopub.execute_input":"2024-04-18T14:42:39.686514Z","iopub.status.idle":"2024-04-18T14:42:40.725205Z","shell.execute_reply.started":"2024-04-18T14:42:39.686475Z","shell.execute_reply":"2024-04-18T14:42:40.723430Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"np: 1.26.4\npd: 2.2.1\nsklearn: 1.2.2\nlibrosa: 0.10.1\ntf: 2.15.0\ntfio: 0.35.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf:\u001b[39m\u001b[38;5;124m'\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfio:\u001b[39m\u001b[38;5;124m'\u001b[39m, tfio\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw&b:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n","\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"],"ename":"NameError","evalue":"name 'wandb' is not defined","output_type":"error"}]},{"cell_type":"code","source":"class CFG:\n    # Debugging\n    debug = False\n    \n    # Verbosity level\n    verbose = 1\n    \n    # Plot training history\n    training_plot = True\n    \n    # Weights and Biases logging\n    wandb = True\n    competition   = 'birdclef-2023' \n    _wandb_kernel = 'awsaf49'\n    \n    # Experiment name and comment\n    exp_name = 'birdclef-pretrain-v3'\n    comment = 'EfficientNetB1|No-FSR|t=10s|128x384|cutmix'\n    # Notebook link\n    notebook_link = 'https://www.kaggle.com/awsaf49/birdclef23-pretraining-is-all-you-need-train'\n    \n    # Device and random seed\n    device = 'TPU-VM'\n    seed = 42\n    \n\n    # Input image size and batch size\n    img_size = [128, 384]\n    batch_size = 32\n    upsample_thr = 50 # min sample of each class (upsample)\n    cv_filter = True # always keeps low sample data in train\n    \n    # Audio duration, sample rate, and length\n    duration = 10 # second\n    sample_rate = 32000\n    audio_len = duration*sample_rate\n    \n    # STFT parameters\n    nfft = 2028\n    window = 2048\n    hop_length = audio_len // (img_size[1] - 1)\n    fmin = 20\n    fmax = 16000\n    normalize = True\n    \n    # Inference batch size, test time augmentation, and drop remainder\n    infer_bs = 2\n    tta = 1\n    drop_remainder = True\n    \n    # Number of epochs, model name, and number of folds\n    epochs = 25\n    model_name = 'EfficientNetB1'\n    fsr = False # reduce stride of stem block\n    num_fold = 5\n    \n    # Selected folds for training and evaluation\n    selected_folds = [0]\n\n    # Pretraining, neck features, and final activation function\n    pretrain = 'imagenet'\n    neck_features = 0\n    final_act = 'softmax'\n    \n    # Learning rate, optimizer, and scheduler\n    lr = 1e-3\n    scheduler = 'cos'\n    optimizer = 'Adam' # AdamW, Adam\n    \n    # Loss function and label smoothing\n    loss = 'CCE' # BCE, CCE\n    label_smoothing = 0.05 # label smoothing\n    \n    # Data augmentation parameters\n    augment=True\n    \n    # Time Freq masking\n    freq_mask_prob=0.50\n    num_freq_masks=1\n    freq_mask_param=10\n    time_mask_prob=0.50\n    num_time_masks=2\n    time_mask_param=25\n\n    # Audio Augmentation Settings\n    audio_augment_prob = 0.5\n    \n    mixup_prob = 0.65\n    mixup_alpha = 0.5\n    \n    cutmix_prob = 0.65\n    cutmix_alpha = 2.5\n    \n    timeshift_prob = 0.0\n    \n    gn_prob = 0.35\n\n    # Class Labels for BirdCLEF 23\n    class_names = sorted(os.listdir('/kaggle/input/birdclef-2024/train_audio/'))\n    num_classes = len(class_names)\n    class_labels = list(range(num_classes))\n    label2name = dict(zip(class_labels, class_names))\n    name2label = {v:k for k,v in label2name.items()}\n    \n    # Class Labels for BirdCLEF 21 & 22\n    class_names2 = sorted(set(os.listdir('/kaggle/input/birdclef-2021/train_short_audio/')\n                       +os.listdir('/kaggle/input/birdclef-2022/train_audio/') \n                              +os.listdir('/kaggle/input/birdclef-2023/train_audio/')\n                       +os.listdir('/kaggle/input/birdsong-recognition/train_audio/')))\n    num_classes2 = len(class_names2)\n    class_labels2 = list(range(num_classes2))\n    label2name2 = dict(zip(class_labels2, class_names2))\n    name2label2 = {v:k for k,v in label2name2.items()}\n\n   \n    # Training Settings\n    target_col = ['target']\n    tab_cols = ['filename']\n    monitor = 'auc'","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:37:23.448209Z","iopub.status.idle":"2024-04-18T14:37:23.448585Z","shell.execute_reply.started":"2024-04-18T14:37:23.448390Z","shell.execute_reply":"2024-04-18T14:37:23.448407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:37:23.449393Z","iopub.status.idle":"2024-04-18T14:37:23.449725Z","shell.execute_reply.started":"2024-04-18T14:37:23.449566Z","shell.execute_reply":"2024-04-18T14:37:23.449583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if \"TPU\" in CFG.device:\n    tpu = 'local' if CFG.device=='TPU-VM' else None\n    print(\"connecting to TPU...\")\n    try:\n       \n        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\n        tf.tpu.experimental.initialize_tpu_system(resolver)\n        strategy = tf.distribute.TPUStrategy(resolver)\n        \n    except Exception as e:\n        print(e)\n        CFG.device = \"GPU\"\n        \nif CFG.device == \"GPU\"  or CFG.device==\"CPU\":\n    ngpu = len(tf.config.experimental.list_physical_devices('GPU'))\n    if ngpu>1:\n        print(\"Using multi GPU\")\n        strategy = tf.distribute.MirroredStrategy()\n    elif ngpu==1:\n        print(\"Using single GPU\")\n        strategy = tf.distribute.get_strategy()\n    else:\n        print(\"Using CPU\")\n        strategy = tf.distribute.get_strategy()\n        CFG.device = \"CPU\"\n\nif CFG.device == \"GPU\":\n    print(\"Num GPUs Available: \", ngpu)\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nCFG.replicas = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {CFG.replicas}')\nCFG.device","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:37:23.450419Z","iopub.status.idle":"2024-04-18T14:37:23.450706Z","shell.execute_reply.started":"2024-04-18T14:37:23.450573Z","shell.execute_reply":"2024-04-18T14:37:23.450588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH0 = '/kaggle/input/birdsong-recognition'\nBASE_PATH1 = '/kaggle/input/birdclef-2021'\nBASE_PATH2 = '/kaggle/input/birdclef-2022'\nBASE_PATH3 = '/kaggle/input/birdclef-2023'\nBASE_PATH4 = '/kaggle/input/xeno-canto-bird-recordings-extended-a-m'\nBASE_PATH5 = '/kaggle/input/xeno-canto-bird-recordings-extended-n-z'\nBASE_PATH6 = '/kaggle/input/birdclef-2024'\n\n# This gets the Google Cloud Storage paths, if we are using TPU.\nif CFG.device==\"TPU\":\n    from kaggle_datasets import KaggleDatasets\n    GCS_PATH0 = KaggleDatasets().get_gcs_path(BASE_PATH0.split('/')[-1])\n    GCS_PATH1 = KaggleDatasets().get_gcs_path(BASE_PATH1.split('/')[-1])\n    GCS_PATH2 = KaggleDatasets().get_gcs_path(BASE_PATH2.split('/')[-1])\n    GCS_PATH3 = KaggleDatasets().get_gcs_path(BASE_PATH3.split('/')[-1])\n    GCS_PATH4 = KaggleDatasets().get_gcs_path(BASE_PATH4.split('/')[-1])\n    GCS_PATH5 = KaggleDatasets().get_gcs_path(BASE_PATH5.split('/')[-1])\n    GCS_PATH6 = KaggleDatasets().get_gcs_path(BASE_PATH6.split('/')[-1])\nelse:\n    GCS_PATH0 = BASE_PATH0\n    GCS_PATH1 = BASE_PATH1\n    GCS_PATH2 = BASE_PATH2\n    GCS_PATH3 = BASE_PATH3\n    GCS_PATH4 = BASE_PATH4\n    GCS_PATH5 = BASE_PATH5\n    GCS_PATH6 = BASE_PATH6","metadata":{},"execution_count":null,"outputs":[]}]}